ninja_required_version = 1.3
cxx = c++

cflags = -DTORCH_EXTENSION_NAME=cublas -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -isystem /home/trung/gpu/.venv/lib/python3.12/site-packages/torch/include -isystem /home/trung/gpu/.venv/lib/python3.12/site-packages/torch/include/torch/csrc/api/include -isystem /home/trung/gpu/.venv/lib/python3.12/site-packages/torch/include/TH -isystem /home/trung/gpu/.venv/lib/python3.12/site-packages/torch/include/THC -isystem /home/trung/miniconda3/include/python3.12 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -O2
post_cflags = 
cuda_dlink_post_cflags = 
ldflags = -shared -lcublas -L/home/trung/gpu/.venv/lib/python3.12/site-packages/torch/lib -lc10 -ltorch_cpu -ltorch -ltorch_python

rule compile
  command = $cxx -MMD -MF $out.d $cflags -c $in -o $out $post_cflags
  depfile = $out.d
  deps = gcc



rule link
  command = $cxx $in $ldflags -o $out

build cublas.o: compile /home/trung/gpu/kernels/cublas.cpp



build cublas.so: link cublas.o

default cublas.so
